\documentclass{article}
%\usepackage[utf8]{inputenc}
\usepackage[total={5.5in,9.5in}]{geometry}
\usepackage{fontspec}
\usepackage{unicode-math}
\usepackage{xspace}
\usepackage{graphicx}
%\usepackage{palatino}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
%\usepackage{gitinfo2}

\setmathfont{STIX2Math}[
Extension={.otf},
Path=./STIX2fonts/,
Scale=1]
\setmainfont{STIX2Text}[
Extension={.otf},
Path=./STIX2fonts/,
UprightFont={*-Regular},
BoldFont={*-Bold},
ItalicFont={*-Italic},
BoldItalicFont={*-BoldItalic}]

\setmonofont{Courier}
\newfontfamily{\courier}{Courier}
\setmonofont{Ubuntu}
\newfontfamily{\ubuntu}{Ubuntu}
\lstset{
  basicstyle=\ubuntu\scriptsize
}

\hypersetup{colorlinks=true,linkcolor=blue,citecolor=violet}

\newcommand{\map}{\textsc{map}\xspace}
\newcommand{\foi}{\textsc{foi}\xspace}
\newcommand{\eir}{\textsc{eir}\xspace}
\newcommand{\ramp}{\textsc{ramp}\xspace}
\newcommand{\pfpr}{Pf\textsc{pr}\xspace}
\newcommand{\ihme}{\textsc{ihme}\xspace}

\title{Tourist Index in Movement Models}
\author{adolgert@uw.edu}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
This is about incorporating the tourist index into movement models. Dave sent me an idea, which is copied as Sec.~\ref{sec:davedesk}. There are a couple of equations I added from references, but that's it. We can do a simple calculation of tourist index in Sec.~\ref{sec:calculatetourist}. Then we'll think about how to add it as a covariate to an inference model.

If we start with notation from Daniel's paper~\cite{Citron2021-jt}, then an Eulerian movement model is
\begin{equation}
  \frac{dN_i}{dt} = -\sum_{j=1}^K f_{i,j} N_i + \sum_{j=1}^K f_{j,i} N_j\label{eqn:citron1}
\end{equation}
where $N_i$ are hosts at site $i$, there are $K$ sites, the total number of hosts is constant over time, and $f_{i,j}$ is a rate for hosts at $i$ to travel to $j$. We fix $f_{i,i}=0$ so there is no self-travel. A fully-specified Flux model requires $K(K-1)$ parameters because it's a $K$ by $K$ matrix of fluxes, minus the diagonal.

\section{From the Desk of Dave Smith}\label{sec:davedesk}
If we carved up space into a sensible set of populated patches, we want to form a time spent / time at risk matrix that describes, on average, how much time a person from here spends there.
(I can write this out in much more specific notation, but think about the problem of parameterizing Host movement model for Simple Trip,
\begin{eqnarray}
\frac{dN_{i,i}}{dt}&=&-\sum_{j=1}^K \phi_{i,j}N_{i,i} + \sum_{j=1}^K \tau_{i,j}N_{i,j} \\
\frac{dN_{i,j}}{dt}&=&-\tau_{i,j}N_{i,j}+\phi_{i,j}N_{i,i}\label{eqn:citron2}
\end{eqnarray}
and getting the steady states
\begin{eqnarray}
N_{i,i}^* & = & \frac{1}{1+\sum_{k=1}^K\frac{\phi_{i,k}}{\tau_{i,k}}}N_i \\
N_{i,j}^* & = & \frac{\phi_{i,j}}{\tau_{i,j}} \frac{1}{1+\sum_{k=1}^K\frac{\phi_{i,k}}{\tau_{i,k}}} N_i\label{eqn:citron3}
\end{eqnarray}
from our \textsc{pnas} paper led by Daniel~\cite{Citron2021-jt}.) [In this model, $\phi_{i,j}$ is the rate at which hosts whose home is $i$ travel to $j$ and $\tau_{i,j}$ is the rate of return.]
Let's call the population-normalized steady states of Eq.~\ref{eqn:citron3} the time at risk matrix, $\Psi$. We'll let $N$ be the vector of population densities.
Note that \verb|t(Psi) N| gives me a vector describing the ambient population here.
And lets call \verb|t(Psi) \%*\% N  / N| the tourist index.
It's the ratio of the ambient population to the resident population.
We want to parameterize TaR matrices, so we use some simple rules. Each patch has a size, position, and population density, so we predict who goes where based on (usually) a simple parametric model: e.g. gravity, or radiation.
What if, instead, we started by putting constraints on something like the tourist index, and then we worked back to ask where people came from?
...so the idea for a paper would be to find several published models and compute the tourist index.
ya. I was thinking the one by John Marshall that Sean and Hector were on, for starters~\cite{Marshall2018-wf}.
It's always been hard to formulate travel and check models for gridded population models.
I guess the main idea is really any one of three:
\begin{enumerate}
  \item formulate a model for time at risk that explicitly constrains the tourist index;
  \item formulate models that impose some relationship between covariates and the tourist index and generate time at risk; or 
  \item examine the relationships between the tourist index and covariates in published models.
\end{enumerate}
Before we jumped in feet first, I guess we define a small pilot study and get the lay of the land. The John Marshall\textsuperscript{+} paper is good.


\section{Calculate Some Tourist Indices}\label{sec:calculatetourist}

\subsection{From the Marshall Paper on Mathematical Models}

This paper~\cite{Marshall2018-wf} uses travel data from four countries to evaluate distance kernels for movement. It doesn't use data about the duration of trips and doesn't give trip duration data to readers. For each distance kernel, they fit to find the best parameters, and those parameters are in a table. So this has:
\begin{itemize}
  \item Distance kernels.
  \item Parameter choices for those distance kernels.
  \item Coordinates for population centers and populations at those centers.
\end{itemize}
It's a great paper with great data. What can we do with it?
\begin{enumerate}
  \item Calculate the tourist index for the given kernels, on the given landscapes, with given parameters. This would require adding a length of stay or a distribution of lengths of stay.

  \item Use an estimate of the tourist index to estimation of parameters. Do this by making a prior on the tourist index and including it in the likelihood.
\end{enumerate}
Let's start with the simpler calculation.

\subsection{Relate two travel models}

I don't know the proper term to differentiate a gravity model from a simple trip model. The gravity model is a likelihood for each destination, but it doesn't have a rate of travel. We will see here that we need to add two rates in order to configure a simple trip model from a gravity model.

If we work from a simple trip model, we can consider our core vector to be the total population whose home is each site $i$, $N_i=\sum_j N_{ij}$. Then time time-at-risk matrix is
\begin{equation}
  \psi_{ij}=\frac{N_{ij}}{N_i}.
\end{equation}
This means that all foreigners living at destination $j$ can be written in terms of $\psi$,
\begin{equation}
  \sum_i N_{ij} = \sum_i N_i\psi_{ij}.
\end{equation}
The \emph{tourist index} is that, normalized by the local population.
\begin{equation}
  b_j = \frac{\sum_i N_{ij}}{N_{j}} = \sum_i \frac{N_i\psi_{ij}}{N_{j}}.
\end{equation}
I'm using $b_j$ for the tourist index because $\tau$ is taken, $t$ is always time, and it reminds me of the word \emph{badaud}, which is a silly part of being a tourist. I'm a little unclear on how to normalize the tourist index. We could normalize it by total people at a place, $N_{jj} + \sum_i N_{ij}$. This would give us the right probability if we choose a random person in a place and ask if this is their home. For approximations, we can use $N_j$ or $N_{jj}$, which are people from a place and people from a place who are currently sleeping there.

If we have a distance kernel, $k_{ij}$, then we can relate that to rates, up to a constant of proportionality.
\begin{equation}
  \frac{k_{ij}}{\sum_j k_{ij}} = \frac{\phi_{ij}}{\sum_j \phi_{ij}}
\end{equation}
We can supply that constant if we look up the probability of travel, which the Marshall et al paper discusses at the end of their data section. They use Demographic and Health Surveys (DHS) to estimate how often people travel and stay overnight.

\subsection{Analyze sample data}

Given the data we have, what steps do we need to do?
\begin{enumerate}
  \item Pick a rate at which people travel anywhere (2 trips per year, so 2/365). Pick a rate of return, $\tau_{ij}$. This can be five-day trips, so 1/5.
  \item Calculate $k(i,j)$ for each point in the Excel file by summing over all kernel values and using that as a normalization.
  \item Calculate $N_{ij}$ for each point, and sum it to get total visitors.
\end{enumerate}
The result is in Fig.~\ref{fig:tantour}.

\begin{figure}
\centering\includegraphics[width=8cm]{tanzania_tourists.png}
\caption{This histogram shows that the tourist index is mostly less than 0.2, with only three outliers, for the Tanzania dataset and parameters from the Marshall paper. It was computed using a repository called \texttt{tourist}.\label{fig:tantour}}
\end{figure}

This quick calculation exercise leads me to observe that, for the simple trip model combined with a gravity model, the ratio of trip frequency to return frequency will determine the time-at-risk matrix. The tourist index would be a one-parameter constraint that ratio. If the simple trip model has $2K(K-1)$ parameters, then we determine them with the $K(K-1)$ parameters given by the gravity model, the $K(K-1) - 1$ parameters from our assertion that $\tau_{i,k}$ is a constant value, and by asserting a value for the single $\sum\phi/\tau$ ratio.

Having calculated the tourist index, and having seen how many parameters it needs, we can think about how to infer a travel model, given the tourist index. That would start with making a likelihood.


\section{Construct a Likelihood}

This section asks how we would infer parameters for a travel model that includes data on the tourist index. This section is incomplete.

\subsection{Destination model likelihood}

This likelihood is simple. Each trip has a choice about where to go. Label trips with $r$.
\begin{equation}
  \prod_{r} \left(\frac{k_{ij}}{\sum_{j} k_{ij}}\right)^{N_r}\label{eqn:destinationlikelihood}
\end{equation}
Let's start with this per-trip probability and write a few things we know, in order to work up to a likelihood that's written in terms of the parameters we want.

\subsection{Simple trip for indistinguishable counts}

We are thinking about a simple trip model. This has a set of interchangeable individuals at sites. Each set of individuals has a home site. When an individual travels to another site, they always return home, not to any other site. There is no interaction among individuals.

The state of the system is the number of individuals at each home site and, for each home site, the number of individuals at each other home site. If the individuals were distinguishable, so we were to talk about one individual, there would be $K^2$ states. Here, there are $K^2$ counts of individuals where each set of $K$ counts adds up to all individuals whose home is one site. These $K^2$ counts are the $N_{ij}$.

In the original problem, without the tourist index, each set of $K$ transitions doesn't interact. Adding a constraint on the tourist index creates an interaction among them. We might be able to write the system as a Kronecker product of simpler systems and then break that symmetry with the tourist constraint.

\subsection{Simple trip for individuals}

Given that there is no interaction among individuals, another way to compute properties of a simple trip is to use individual likelihoods and build up from there.

If we're calculating a single trip with a rate, then the cumulative probability is an exponential distribution.
\begin{equation}
  F(j, t|i) = 1-\frac{k_{ij}}{\sum_jk_{ij}} e^{-\sum_j\lambda_{ij}t}\label{eqn:exponentialsingle}
\end{equation}
Here, the $\lambda_{ij}$ is the rate of trips from $i$ to $j$. It would be $\phi_{ij}$ on the way out and $\tau_{ij}$ on the way back. Note that the exponential factor is the survival until someone leaves the home, also known as the waiting time. If you're thinking about a sequence of these trips, you should be thinking about the Sellke construction.

For a single hop, the likelihood is the pdf of Eq.~\ref{eqn:exponentialsingle}.
\begin{equation}
  f(j, t|i) = \frac{k_{ij}\sum_j\phi_{ij}}{\sum_jk_{ij}} e^{-\sum_j\phi_{ij}t}\label{eqn:pdfsingle}
\end{equation}
If we go out and back with $\phi$ and $\tau$, then each trip has two parts.
\begin{equation}
  f_s(j, t|i) = \frac{k_{ij}\tau_{ij}\sum_j\phi_{ij}}{\sum_jk_{ij}} e^{-\sum_j\phi_{ij}t}e^{-\tau_{ij}t}\label{eqn:pdfsimple}
\end{equation}
If we compute the likelihood of a set of trips, it's the product of these above. All of the time dependence becomes a single term in the log-likelihood, leaving the same calculation as Eq.~\ref{eqn:destinationlikelihood} for the choice of where to travel.

Recall how a single-hop CDF for an exponentially-distributed stochastic process becomes the likelihood of having $m$ jumps in a time $t$. The maximum likelihood of $m$ is $d/dn$ of $\prod f(j,t|i)$. In this case, for the tourist index, you're doing a similar likelihood calculation, but looking at the sum of all transitions into a destination.


\subsection{Disconnect preference from observation}

A simple way to state this problem is to say that there are some place people prefer to go. While each gravity model is independent, the covariate driving the tourist covariate would be shared among gravity models. In this case, we assert a form for the likelihood of travel and calculate its effect on tourist index.

The tourist index would be covariate-driven and could modify the rate for travel to a location.
\begin{equation}
  \lambda = \phi_{ij} + \beta X_{j}
\end{equation}
It might make sense to make it proportional.
\begin{equation}
  \lambda = \phi_{ij}(1 + \beta X_{j})
\end{equation}
We could guarantee it not be negative by using Cox proportional hazards.
\begin{equation}
  \lambda = \phi_{ij}\exp\left(\beta X_{j}\right)
\end{equation}
If we choose one of these forms, what does it do to the tourist index?

The tourist index can be computed from a few similar starting equations. We might have to try different ones to see which works best. Let's start by writing the most intuitive, that it's foreign people in a place, divided by all people in a place. This corresponds to a news report, ``one out of every three people in Santa Monica is from somewhere else.''
\begin{equation}
 b_j = \frac{\sum_{i\ne j} N_{ij}}{\sum_i N_{ij}}\label{eqn:touristexact}
\end{equation}
We know the steady-state $N_{ij}$ from Eq.~\ref{eqn:citron3}. Let's designate $\exp\left(\beta X_{j}\right)$ with $T_j$ and label the new steady state with a prime.
\begin{eqnarray}
N_{i,i}' & = & \frac{1}{1+\sum_{k=1}^K\frac{\phi_{i,k}T_k}{\tau_{i,k}}}N_i \\
N_{i,j}' & = & \frac{\phi_{i,j}T_j}{\tau_{i,j}} N_{i,i}'\label{eqn:touriststable}
\end{eqnarray}
Plug into Eq.~\ref{eqn:touristexact}.
\begin{equation}
b'_j = \frac{\sum_{i\ne j}N_{ij}'}{N'_{jj}+\sum_{i\ne j} N_{ij}'}
\end{equation}
Maybe this simplifies. It isn't obvious to me from here.

We could make the tourist index simplify by requiring that tourist index not change the total rate at which someone leaves a site. This would mean the sum doesn't change.
\begin{equation}
\sum_{k=1}^K\frac{\phi_{i,k}T_k}{\tau_{i,k}} = \sum_{k=1}^K\frac{\phi_{i,k}}{\tau_{i,k}}
\end{equation}
This could be achived by introducing an offsetting constant.
\begin{equation}
  \lambda_{ij} = \phi_{ij}\exp\left(\beta X_{j} + H_i\right)
\end{equation}
It's always possible to find an offsetting constant because we're asking the dot product of two vectors to remain constant, so we're defining a planar subspace, and the constant changes the length of the vector to meet that subspace. This wouldn't quite collapse the equation to be exactly the tourist index, though. I should look at this more.


\section{Pilot}
I propose that we fit to synthetic data, in order to see that a fit can happen. That means I choose a functional form for the destination model and the tourist index, generate from it, and then fit to it. We can do a sequence of progressively more difficult fits.
\begin{enumerate}
  \item The model of one site has no tourist index. Fit that.
  \item The model of one site has a tourist index and data about tourists from that one site.
  \item The model has many sites and tourist index data for each source site, so they are independent. Do this fit in order to see memory requirements.
  \item The model has many sites and tourist index that is a sum of all tourists.
  \end{enumerate}

\subsection{Example of inference}
As an example of the kind of calculation we could do, I made some synthetic data for a travel model and then fit it using probabilistic programming.

This is a gravity model, just that, but I'm not fitting it with a likelihood. I'm fitting it the way we would have to fit the other models, by sampling parameters and simulating an outcome.

In this code, a \verb|TArray| is just an array. The input data is an array, $x$,  of how many trips went to each of $K$ sites. The model is written using a package called Turing.jl.
\begin{lstlisting}
@model function gravity_model(x, ::Type{T} = Float64) where {T <: Real}
    s ~ InverseGamma(2, 3)  # error on observation.
    a ~ Gamma(2, 3)
    r ~ Gamma(2, 0.2)
    k = TArray(T, K)
    for kidx in 1:K
        # The gravity model.
        k[kidx] = Nj[kidx] * (one(T) + distance[kidx] / r)^(-a)
    end
    ktotal = sum(k)

    for dest_idx in 1:K
        x[dest_idx] ~ Normal(1000 * k[dest_idx] / ktotal, 1000 * sqrt(s))
    end
end

chn = sample(gravity_model(trips), HMC(0.1, 5), 1000)
\end{lstlisting}
The fit isn't great with these priors. I need to plot some things, be more careful.

I'm wondering what data we should assume for a travel model that has tourist covariates. That would determine the form of this kind of inference.

\section{Do City Sizes Matter?}

Does it matter whether we fit a travel model to aggregated data instead of fitting it to better-resolved data? When I started to make synthetic data for the pilot model, I wondered how to distribute sites spatially and how to assign populations. The Marshall paper looks at populations aggregated to an admin level. I know that there are studies on city sizes that look at different distributions~\cite{giesen2010size,eeckhout2004gibrat}.

One paper constructs cities from data using an algorithm~\cite{rozenfeld2008laws,rozenfeld2011area}. ``To define
a CCA cluster, we first locate a populated site. Then, we recursively grow the cluster by
adding all nearest-neighbor sites (populated sites within a distance smaller than the coarsegraining level, $l$, from any site within the cluster) with a population density, $D$, larger than
a threshold $D^∗$. The cluster stops growing when no site outside the cluster with population
density $D > D^∗$ is at a distance smaller than $l$ from the cluster boundary.''

We could investigate this question numerically.
\begin{enumerate}
  \item Generate a set of sites with populations from Zipf's law, which is the Pareto distribution. Place them on a surface. Make travel distributions from a kernel, and make sample data from that.
  \item Create copies of the same data using clustering. Put the same sample data onto this aggregated set of sites.
  \item Infer parameters for a movement kernel from the sites themselves and from several levels of aggregation.
\end{enumerate}
I'd want to do this for several samples to see a trend.


\section{Influence Curve}

Sean Wu asked about the influence curve of the tourist index. An influence curve is a way to determine how much an estimated value is affected by changes to the data. We're looking at this tourist index as a way to make data more reasonable, so maybe the influence curve is a good way to think about reasonableness of a dataset. Let's start by defining the influence curve.

\subsection{Influence Curves}

The most common example of an influence curve comes from its definition in Hampel's original article~\cite{hampel1974influence}. If you start with values, $x_i$, taken from a distribution, $F$, and the estimate of the mean is $\overbar{x} = \sum_i x_i / n$. If you add a point at a new location, $x$, the new mean is $(x-\overbar{x})/(n+1).$ The influence curve is how much the mean changes when you add a value.

Hampel's definition defines the influence curve as a small change in an estimator, $T$, given a small change in the underlying distribution $F$. Because $F$ is multidimensional, the small change in $F$ is directional. He defines a change that is as small as $\epsilon$ in the $\delta_\omega$ direction.
\begin{equation}
  \mbox{IC}_{T,F}(\omega)=\mbox{lim}\left\{T[(1-\epsilon)F+\epsilon\delta_\omega]-T(F)\right\}/\epsilon.
\end{equation}
That helps with simple estimators. There is a more expansive, and clearer, discussion in Efron~\cite{efron1982jackknife}. He points out that the influence function is related to the jacknife and bootstrap methods. Those methods estimate uncertainty in an estimate of small-sample data. They do it by looking at values near the mean of the estimator. The influence function is part of a Taylor expansion of the estimator. Here, the estimator is $\theta$, the distribution is $F$, the empirical distribution is $\hat{F}$, and $X_i$ is a draw from $F$.
\begin{equation}
  \theta(\hat{F})=\theta(F) + \frac{1}{n}\sum_{i=1}^{n} \mbox{IF}(X_i) + O_p\left(1/n\right)
\end{equation}
That makes the influence curve the partial derivative of the estimator with respect to the data.

I'm confused about how to use this definition for our problems because we usually have a single draw from an underlying distribution, not multiple draws. (This is addressed in Koh and Liang~\cite{koh2017understanding}, and the distributions are handled in Levy~\cite{levy2019tutorial}.) It's a spatial process to define points and a covariance on all points. Maybe that idea is holding me back. I should think about the observed data as a draw. Hold the spatial location and population count fixed, and the tourist covariate is a draw from an underlying distribution. Or is it the movement to that location should be the draw?


\subsection{Problem Statement}

Maybe we can get clearer about what we're doing. That means we define the model by defining the stochastic process and the data. We can ask about the tourist index using the destination kernel, not the full Simple Trip travel model, so let's use the simpler model. The data is
\begin{enumerate}
  \item Site location in $(x,y)$, population $N_i$.
  \item Number of trips from site 0 to site $j$ for all $j\ne 0$.
  \item Tourist index, which is a covariate that affects desirability of each site.
  \item Tourist trips to each site, $j$, which is the sum of trips from all starting sites to site $j$.
  \end{enumerate}
The fourth item is the tourist index, stated as a number of trips instead of a percentage of the population. Those two quantities are proportional, related by the average length of a stay.

Take a gravity kernel
\begin{equation}
k(d_{i,j}) = \left(1+\frac{d_{i,j}}{\rho}\right)^{-\alpha}
\end{equation}
which inserts into a destination probability $P(j|i)\propto N_j^{\tau}k(d_{i,j})$. We can set $\tau=1$ and then vary it later. For our tourist model,
\begin{equation}
  P(j|i) = \frac{k(d_{i,j})\exp(\beta X_j)}{\sum_{j} k(d_{i,j})\exp(\beta X_j)}.
\end{equation}

In order to use the tourist index, we need to calculate $P(j|i)$ for \emph{every site}. Then sum the number of trips to each site, according to the current kernel. It should be quadratic in the number of sites, which is much more computationally intensive.

How can we get an influence curve? Generate data from a tourist model. Fit without a tourist model. Then introduce a covariate on one place? If we set a small value for the covariate, then that doesn't do much because it would just give us a larger $\beta$. Or do we add a site and see how that affects the estimate?


\subsection{Using Tourist Estimates to Regularize the Kernel}

Will the models produce less extreme values than models without the tourist index? These are gravity models with a multiplicative covariate. That covariate drives outbound travel, so it puts weights on destinations. This doesn't seem like it will limit the total number of inbound people, which is the number that can be ridiculous with a travel model.

Can we solve the model from the opposite direction? What if we knew the number of people visiting each place? Could we then guess a distance kernel? For instance, could we make an empirical distance kernel?

\section{Using Tourists to Regularize Transport}

Our goal is to predict movement without making wild predictions. A pure gravity model, for instance, will make wild predictions when the distance between source and destination is small. The models above, which added a covariate to a gravity model, would still have this problem that nearby destinations would be very large. That problem will remain if we state the model as a gravity model with some modification. This section tries to state the model in a way that will take any transportation, including the gravity model, and make reasonable predictions from it.

We set up our model system with three quantities. There are source sites, $i$. Each source site has a population $p_i$. It has a total number of people who travel during a time period, determined by a travel rate times the population. There are destination sites, which are the same as the source sites, but we label them with $j$ because they have a separate piece of information, the total number of inbound travelers over the time period. These might as well be different sites. Between $i$ and $j$, we set up a transportation network. Each site $i$ is connected to every site $j$ which is not the origin.

There is a classic problem, called the Hitchcock transportation problem, where a set of sources $i$ connect to destinations $j$, with a cost for each $x_{ij}$ transport. The goal is to move source product to meet needs at the destination. Our problem differs in two ways. We don't have a complete set of $i$--$j$ connections because people don't travel to their own site. We also don't have transportation costs. We have, instead, a likelihood that a person travels a certain distance. This distribution comes from the travel model. That gives us an optimization problem that looks less like this transportation problem and more like an Earth-Mover's Distance problem.

If we laber the number of people traveling from $i$ to $j$ as $x_{ij}$, then we need to constrain outbound travelers to match source populations, $\gamma_i p_i = \sum_j x_{ij}$, where $\gamma$ is a rate of travel per person per time interval. We also claim to have a tourist index for places, derived from local population and lodging covariates, so each location constrains $r_j = \sum_i x_{ij}$. We need to pose the problem so that the travelers equal the lodgers, $\sum_i \gamma_i p_i = \sum_j r_j$, or there won't be a feasible solution.

The objective of this travel model is to ensure people generally obey the gravity model (or other) while not overwhelming the tourist index. The gravity model provides a distribution of how many people would travel to each site, and that distribution is decided by distance. That gravity model provides a distribution over destinations for each origin, so it overdetermines the system. We can minimize the deviation from those distributions.

We will take the gravity model as a set of priors on the distribution of travel destinations.
\begin{equation}
  d_{ij} \sim \mbox{Dirichlet}(k_{ij})
\end{equation}
Here, the $k_{ij}$ are the probability of going from $i$ to $j$. Then we use the tourist index as a single observation of where people go. It is a sum over travelers from all sources.
\begin{equation}
  r_i \sim \mbox{N}\left(\sum_{j\ne i} p_j d_{ij}, \sigma \right)
\end{equation}
The $p_j$ is the source population. Each tourist index, $r_i$, is a count of incoming travelers. We assume this has a Gaussian error.

Those two equations above are enought to take a distance kernel as a prior and soften its extreme peaks so that they agree with numbers of travelers to a destination. They can be solved with a Hamiltonian Monte Carlo. The output is a distribution of Dirichlet parameter draws. If you want a sample of travel, you draw from the parameter posteriors, then use those to draw a number of travelers from a Dirichlet distribution. See Fig.~\ref{fig:hmc-posterior} for posteriors from a run with six sites, doing 10,000 samples.

\begin{figure}
\includegraphics[height=8in]{dirichlet_driven.png}
\caption{For six sites, there are $6\times 5$ kernel probabilities. These are posteriors for those from HMC.\label{fig:hmc-posterior}}
\end{figure}
\bibliographystyle{ieeetr}
\bibliography{tourist}
\end{document}
